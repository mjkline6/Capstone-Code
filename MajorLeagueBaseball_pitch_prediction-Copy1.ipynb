{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Machine Learning Senior Capstone\n",
    "### Predicting pitches in Major League Baseball \n",
    "#### Code Contributors: Dylan Mullican and Matt Kline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch_type</th>\n",
       "      <th>batter</th>\n",
       "      <th>stand</th>\n",
       "      <th>p_throws</th>\n",
       "      <th>balls</th>\n",
       "      <th>strikes</th>\n",
       "      <th>on_3b</th>\n",
       "      <th>on_2b</th>\n",
       "      <th>on_1b</th>\n",
       "      <th>outs_when_up</th>\n",
       "      <th>inning</th>\n",
       "      <th>inning_topbot</th>\n",
       "      <th>pitcher</th>\n",
       "      <th>pitch_number</th>\n",
       "      <th>bat_score</th>\n",
       "      <th>fld_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15590</td>\n",
       "      <td>FF</td>\n",
       "      <td>519083</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>571976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Top</td>\n",
       "      <td>477132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15591</td>\n",
       "      <td>FF</td>\n",
       "      <td>519083</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>571976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Top</td>\n",
       "      <td>477132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15592</td>\n",
       "      <td>FF</td>\n",
       "      <td>571976</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Top</td>\n",
       "      <td>477132</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15593</td>\n",
       "      <td>FF</td>\n",
       "      <td>571976</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Top</td>\n",
       "      <td>477132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15594</td>\n",
       "      <td>FF</td>\n",
       "      <td>571976</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Top</td>\n",
       "      <td>477132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pitch_type  batter stand p_throws  balls  strikes  on_3b  on_2b   on_1b  \\\n",
       "15590         FF  519083     R        L      1        0      0      0  571976   \n",
       "15591         FF  519083     R        L      0        0      0      0  571976   \n",
       "15592         FF  571976     R        L      0        2      0      0       0   \n",
       "15593         FF  571976     R        L      0        1      0      0       0   \n",
       "15594         FF  571976     R        L      0        0      0      0       0   \n",
       "\n",
       "       outs_when_up  inning inning_topbot  pitcher  pitch_number  bat_score  \\\n",
       "15590             0       1           Top   477132             2          0   \n",
       "15591             0       1           Top   477132             1          0   \n",
       "15592             0       1           Top   477132             3          0   \n",
       "15593             0       1           Top   477132             2          0   \n",
       "15594             0       1           Top   477132             1          0   \n",
       "\n",
       "       fld_score  \n",
       "15590          0  \n",
       "15591          0  \n",
       "15592          0  \n",
       "15593          0  \n",
       "15594          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Kershaw_15_to_20.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15595, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Shape \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batter</th>\n",
       "      <th>balls</th>\n",
       "      <th>strikes</th>\n",
       "      <th>on_3b</th>\n",
       "      <th>on_2b</th>\n",
       "      <th>on_1b</th>\n",
       "      <th>outs_when_up</th>\n",
       "      <th>inning</th>\n",
       "      <th>pitcher</th>\n",
       "      <th>pitch_number</th>\n",
       "      <th>bat_score</th>\n",
       "      <th>fld_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>15595.000000</td>\n",
       "      <td>15595.000000</td>\n",
       "      <td>15595.000000</td>\n",
       "      <td>15595.000000</td>\n",
       "      <td>15595.000000</td>\n",
       "      <td>15595.000000</td>\n",
       "      <td>15595.000000</td>\n",
       "      <td>15595.000000</td>\n",
       "      <td>15595.0</td>\n",
       "      <td>15595.000000</td>\n",
       "      <td>15595.000000</td>\n",
       "      <td>15595.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>532664.498172</td>\n",
       "      <td>0.772684</td>\n",
       "      <td>0.939981</td>\n",
       "      <td>31951.112793</td>\n",
       "      <td>72733.540366</td>\n",
       "      <td>127535.000834</td>\n",
       "      <td>0.967938</td>\n",
       "      <td>3.852837</td>\n",
       "      <td>477132.0</td>\n",
       "      <td>2.846105</td>\n",
       "      <td>0.861173</td>\n",
       "      <td>1.772940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>78536.558497</td>\n",
       "      <td>0.911119</td>\n",
       "      <td>0.827645</td>\n",
       "      <td>127115.678051</td>\n",
       "      <td>185042.118420</td>\n",
       "      <td>229715.675376</td>\n",
       "      <td>0.814372</td>\n",
       "      <td>2.046705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.707190</td>\n",
       "      <td>1.141756</td>\n",
       "      <td>2.080079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>112526.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>477132.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>457803.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>477132.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>542583.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>477132.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>595879.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>477132.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>671250.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>668942.000000</td>\n",
       "      <td>669374.000000</td>\n",
       "      <td>671250.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>477132.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              batter         balls       strikes          on_3b  \\\n",
       "count   15595.000000  15595.000000  15595.000000   15595.000000   \n",
       "mean   532664.498172      0.772684      0.939981   31951.112793   \n",
       "std     78536.558497      0.911119      0.827645  127115.678051   \n",
       "min    112526.000000      0.000000      0.000000       0.000000   \n",
       "25%    457803.000000      0.000000      0.000000       0.000000   \n",
       "50%    542583.000000      1.000000      1.000000       0.000000   \n",
       "75%    595879.000000      1.000000      2.000000       0.000000   \n",
       "max    671250.000000      3.000000      2.000000  668942.000000   \n",
       "\n",
       "               on_2b          on_1b  outs_when_up        inning   pitcher  \\\n",
       "count   15595.000000   15595.000000  15595.000000  15595.000000   15595.0   \n",
       "mean    72733.540366  127535.000834      0.967938      3.852837  477132.0   \n",
       "std    185042.118420  229715.675376      0.814372      2.046705       0.0   \n",
       "min         0.000000       0.000000      0.000000      1.000000  477132.0   \n",
       "25%         0.000000       0.000000      0.000000      2.000000  477132.0   \n",
       "50%         0.000000       0.000000      1.000000      4.000000  477132.0   \n",
       "75%         0.000000       0.000000      2.000000      5.000000  477132.0   \n",
       "max    669374.000000  671250.000000      2.000000      9.000000  477132.0   \n",
       "\n",
       "       pitch_number     bat_score     fld_score  \n",
       "count  15595.000000  15595.000000  15595.000000  \n",
       "mean       2.846105      0.861173      1.772940  \n",
       "std        1.707190      1.141756      2.080079  \n",
       "min        1.000000      0.000000      0.000000  \n",
       "25%        1.000000      0.000000      0.000000  \n",
       "50%        3.000000      0.000000      1.000000  \n",
       "75%        4.000000      1.000000      3.000000  \n",
       "max       12.000000      5.000000     12.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15595,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "#Target Vector\n",
    "y = df['pitch_type']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15595, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Matrix\n",
    "X = df[['bat_score', 'strikes', 'outs_when_up', 'pitch_number', 'on_1b', 'on_2b', 'on_3b', 'batter', 'inning', 'fld_score', 'p_throws', 'pitcher', 'stand', 'inning_topbot', 'balls']]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the text data to numerical\n",
    "df.p_throws = df.p_throws.replace(['R', 'L'], [0,1])\n",
    "df.stand = df.stand.replace(['R', 'L'], [0,1])\n",
    "df.inning_topbot = df.inning_topbot.replace(['Bot', 'Top'], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FF' 'FF' 'SL' ... 'FF' 'FF' 'FF']\n",
      "\n",
      "[[2 0 1 ... 1 0 0]\n",
      " [2 0 0 ... 0 0 0]\n",
      " [2 2 2 ... 0 0 3]\n",
      " ...\n",
      " [0 2 0 ... 0 1 0]\n",
      " [0 1 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#convert features dataframe to a numpy array \n",
    "y = df['pitch_type'].values\n",
    "X = df[['bat_score', 'strikes', 'outs_when_up', 'pitch_number', 'on_1b', 'on_2b', 'on_3b', 'batter', 'inning', 'fld_score', 'p_throws', 'pitcher', 'stand', 'inning_topbot', 'balls']].values\n",
    "print(y)\n",
    "print(\"\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CH', 'CU', 'FF', 'SL'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding the correct labels for each pitch-type classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "l_encoder = LabelEncoder()\n",
    "l_encoder.fit(y)\n",
    "l_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assigning numerical values to pitch labels\n",
    "y_enc = l_encoder.transform(y)\n",
    "np.unique(y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 3 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into a training (75%) and testing (25%) dataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape of the data : (11696, 15)\n",
      "y_train Shape of the data : (11696,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train Shape of the data : {}'.format(X_train.shape))\n",
    "print('y_train Shape of the data : {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test Shape of the data : (3899, 15)\n",
      "y_test Shape of the data : (3899,)\n"
     ]
    }
   ],
   "source": [
    "print('X_test Shape of the data : {}'.format(X_test.shape))\n",
    "print('y_test Shape of the data : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate features from the target for exploration\n",
    "features = df.drop('pitch_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batter</th>\n",
       "      <th>stand</th>\n",
       "      <th>p_throws</th>\n",
       "      <th>balls</th>\n",
       "      <th>strikes</th>\n",
       "      <th>on_3b</th>\n",
       "      <th>on_2b</th>\n",
       "      <th>on_1b</th>\n",
       "      <th>outs_when_up</th>\n",
       "      <th>inning</th>\n",
       "      <th>inning_topbot</th>\n",
       "      <th>pitcher</th>\n",
       "      <th>pitch_number</th>\n",
       "      <th>bat_score</th>\n",
       "      <th>fld_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15590</td>\n",
       "      <td>519083</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>571976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>477132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15591</td>\n",
       "      <td>519083</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>571976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>477132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15592</td>\n",
       "      <td>571976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>477132</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15593</td>\n",
       "      <td>571976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>477132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15594</td>\n",
       "      <td>571976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>477132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       batter  stand  p_throws  balls  strikes  on_3b  on_2b   on_1b  \\\n",
       "15590  519083      0         1      1        0      0      0  571976   \n",
       "15591  519083      0         1      0        0      0      0  571976   \n",
       "15592  571976      0         1      0        2      0      0       0   \n",
       "15593  571976      0         1      0        1      0      0       0   \n",
       "15594  571976      0         1      0        0      0      0       0   \n",
       "\n",
       "       outs_when_up  inning  inning_topbot  pitcher  pitch_number  bat_score  \\\n",
       "15590             0       1              1   477132             2          0   \n",
       "15591             0       1              1   477132             1          0   \n",
       "15592             0       1              1   477132             3          0   \n",
       "15593             0       1              1   477132             2          0   \n",
       "15594             0       1              1   477132             1          0   \n",
       "\n",
       "       fld_score  \n",
       "15590          0  \n",
       "15591          0  \n",
       "15592          0  \n",
       "15593          0  \n",
       "15594          0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a KNN Classification Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (using knn.score() for k = 10 is:0.475\n",
      "Model's Predictive Accuracy for k =10 is: 0.48\n",
      "Misclassified samples for k=10 are 2046\n",
      "\n",
      "Test accuracy (using knn.score() for k = 100 is:0.505\n",
      "Model's Predictive Accuracy for k =100 is: 0.50\n",
      "Misclassified samples for k=100 are 1931\n",
      "\n",
      "Test accuracy (using knn.score() for k = 200 is:0.506\n",
      "Model's Predictive Accuracy for k =200 is: 0.51\n",
      "Misclassified samples for k=200 are 1928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "for k in [10,100,200]:\n",
    "    knn= KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    knn.fit(X_train_std,y_train)\n",
    "    y_pred=knn.predict(X_test_std)\n",
    "\n",
    "    print('Test accuracy (using knn.score() for k = {0} is:{1:0.3f}'.format(k, knn.score(X_test_std, y_test)))\n",
    "\n",
    "    print(\"Model's Predictive Accuracy for k ={0} is: {1:0.2f}\".format(k,metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    print('Misclassified samples for k={0} are {1}\\n'.format(k, (y_pred != y_test).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      " ['SL' 'FF' 'SL' ... 'FF' 'SL' 'FF']\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test_std)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 50.55%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest set accuracy: {0:0.2f}%'.format(100*knn.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class membership probability is: [[0.005 0.235 0.37  0.39 ]\n",
      " [0.005 0.19  0.605 0.2  ]\n",
      " [0.    0.215 0.315 0.47 ]\n",
      " [0.015 0.105 0.69  0.19 ]\n",
      " [0.01  0.11  0.69  0.19 ]\n",
      " [0.    0.17  0.45  0.38 ]\n",
      " [0.    0.1   0.62  0.28 ]\n",
      " [0.    0.105 0.55  0.345]\n",
      " [0.    0.13  0.605 0.265]\n",
      " [0.    0.285 0.33  0.385]]\n"
     ]
    }
   ],
   "source": [
    "print('The predicted class membership probability is: {0}'.format(knn.predict_proba(X_test_std[:10,:])))\n",
    "# Column for each pitch type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.00      0.00      0.00        20\n",
      "          CU       0.36      0.01      0.02       692\n",
      "          FF       0.53      0.78      0.63      1814\n",
      "          SL       0.45      0.40      0.42      1373\n",
      "\n",
      "    accuracy                           0.51      3899\n",
      "   macro avg       0.34      0.30      0.27      3899\n",
      "weighted avg       0.47      0.51      0.45      3899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = ['CH','CU', 'FF', 'SL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Logistic Regression Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and Instantiate the Logistic Regression Model in SciKit-Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='newton-cg',\n",
    "                       multi_class='multinomial',\n",
    "                       random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model by calling fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the test set to create the model's predictions. Name the prediction vector *y_pred* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      " ['FF' 'FF' 'SL' ... 'FF' 'SL' 'FF']\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test_std)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 48.94%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest set accuracy: {0:0.2f}%'.format(100*lr.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's performance accuracy: 0.489\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's performance accuracy: {0:0.3f}\".format(lr.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted probability for belonging to the classes[class 0 = CH, class 1 = CU, class 2 = FF, class 3 = SI, class 4 = SL] are [[2.35406385e-03 1.30844763e-01 4.92500795e-01 3.74300378e-01]\n",
      " [3.24576198e-04 1.76383448e-01 5.98706215e-01 2.24585761e-01]\n",
      " [3.98073451e-03 2.89555021e-01 3.05318276e-01 4.01145969e-01]\n",
      " [8.22496865e-03 9.72989151e-02 6.55902680e-01 2.38573436e-01]\n",
      " [4.31285729e-03 9.23593945e-02 6.23521448e-01 2.79806300e-01]\n",
      " [2.14090583e-06 1.29084814e-01 4.37436087e-01 4.33476959e-01]\n",
      " [2.45243754e-04 6.12928740e-02 7.34467681e-01 2.03994201e-01]\n",
      " [4.22235718e-05 7.31637666e-02 6.11112909e-01 3.15681101e-01]\n",
      " [1.16547270e-03 6.92773344e-02 6.51495210e-01 2.78061982e-01]\n",
      " [5.17469527e-03 1.74410218e-01 4.00382610e-01 4.20032476e-01]]\n"
     ]
    }
   ],
   "source": [
    "print('The predicted probability for belonging to the classes[class 0 = CH, class 1 = CU, class 2 = FF, class 3 = SI, class 4 = SL] are {0}'.format(lr.predict_proba(X_test_std[:10])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.00      0.00      0.00        20\n",
      "          CU       0.31      0.12      0.17       692\n",
      "          FF       0.54      0.75      0.63      1814\n",
      "          SL       0.41      0.34      0.37      1373\n",
      "\n",
      "    accuracy                           0.49      3899\n",
      "   macro avg       0.32      0.30      0.29      3899\n",
      "weighted avg       0.45      0.49      0.45      3899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = ['CH','CU', 'FF', 'SL']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Linear Support Vector Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and instantiate the Linear Support Vector Classifier Model in SciKit-Learn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "lsv = svm.SVC(probability=True, kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model \n",
    "lsv.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the test set to create the model's predictions. Name the prediction vector \"y_pred\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      " ['FF' 'FF' 'SL' ... 'FF' 'SL' 'FF']\n",
      "\n",
      "Test set accuracy: 50.06%\n"
     ]
    }
   ],
   "source": [
    "y_pred = lsv.predict(X_test_std)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))\n",
    "print('\\nTest set accuracy: {0:0.2f}%'.format(100*lsv.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's performance accuracy: 0.501\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's performance accuracy: {0:0.3f}\".format(lsv.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SciKit learn's built-in predict method to test the model's predictive performance for the first row of data in X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00392935, 0.14763314, 0.54407027, 0.30436724]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsv.predict_proba(X_test_std[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples = 1947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of misclassified samples = {0}\\n'.format((y_pred != y_test).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[   0    0   17    3]\n",
      " [   0    0  308  384]\n",
      " [   0    0 1275  539]\n",
      " [   0    0  696  677]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.00      0.00      0.00        18\n",
      "          CU       0.30      0.35      0.32       664\n",
      "          FF       0.54      0.59      0.57      1837\n",
      "          SL       0.39      0.33      0.36      1380\n",
      "\n",
      "    accuracy                           0.45      3899\n",
      "   macro avg       0.31      0.32      0.31      3899\n",
      "weighted avg       0.45      0.45      0.45      3899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = ['CH','CU', 'FF','SL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Build a MLPClassifier Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# Initialize the Multi Layer Perceptron Classifier\n",
    "model=MLPClassifier(solver='adam', alpha=0.005, batch_size=200, epsilon=1e-08, hidden_layer_sizes=(400,),\n",
    "                    learning_rate='adaptive', max_iter=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.005, batch_size=200, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(400,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_iter=700, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FF' 'FF' 'CU' ... 'CU' 'CU' 'SL']\n"
     ]
    }
   ],
   "source": [
    "# Predict for the test set\n",
    "y_pred=model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.19%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted pitch type for this scenario is: CU\n"
     ]
    }
   ],
   "source": [
    "#Predict pitch using in-game scenario displayed in index 22 of dataset\n",
    "print('The predicted pitch type for this scenario is: {}'\n",
    "      .format(model.predict([X_test[22]])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true pitch type is: CU\n"
     ]
    }
   ],
   "source": [
    "print('The true pitch type is: {}'.format(y_test[22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.00      0.00      0.00        18\n",
      "          CU       0.30      0.35      0.32       664\n",
      "          FF       0.54      0.59      0.57      1837\n",
      "          SL       0.39      0.33      0.36      1380\n",
      "\n",
      "    accuracy                           0.45      3899\n",
      "   macro avg       0.31      0.32      0.31      3899\n",
      "weighted avg       0.45      0.45      0.45      3899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = ['CH','CU', 'FF', 'SL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=5,\n",
       "                       n_jobs=None, oob_score=False, random_state=2, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=0)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=2)\n",
    "#Train the model\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      " ['FF' 'FF' 'SL' ... 'FF' 'SL' 'FF']\n",
      "\n",
      "Test set accuracy: 46.55%\n"
     ]
    }
   ],
   "source": [
    "# the difference between X_test_std and X_test\n",
    "# Prediction using X_test_std (std: standard deviation)\n",
    "y_pred = lsv.predict(X_test_std)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))\n",
    "print('\\nTest set accuracy: {0:0.2f}%'.format(100*forest.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FF' 'FF' 'FF' ... 'SL' 'SL' 'CU']\n"
     ]
    }
   ],
   "source": [
    "# Predict for the test set using X_test\n",
    "y_pred=forest.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's performance accuracy: 0.466\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's performance accuracy: {0:0.3f}\".format(forest.score(X_test_std, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
